"""
Thought Loop - Enhanced Background Inner Monologue and Autonomous Thinking

This module creates a comprehensive thought loop system that:
- Runs continuous background inner monologue during idle moments
- Generates spontaneous thoughts, reflections, and expressions of curiosity
- Integrates with existing proactive thinking and inner monologue systems
- Triggers autonomous speech and reflection based on internal states
- Responds to emotional events, unresolved goals, and environmental changes
- Creates authentic consciousness stream with natural thought progression
"""

import threading
import time
import random
import logging
from typing import Dict, List, Any, Optional, Callable, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import json
from pathlib import Path

# Import existing consciousness modules
try:
    from ai.inner_monologue import InnerMonologue, ThoughtType, ThoughtIntensity
    from ai.proactive_thinking_loop import ProactiveThinkingLoop, ProactiveThoughtType
    MONOLOGUE_AVAILABLE = True
except ImportError:
    MONOLOGUE_AVAILABLE = False
    print("[ThoughtLoop] ⚠️ Inner monologue modules not available")

try:
    from ai.mood_manager import get_mood_manager, MoodTrigger
    MOOD_AVAILABLE = True
except ImportError:
    MOOD_AVAILABLE = False
    print("[ThoughtLoop] ⚠️ Mood manager not available")

try:
    from ai.memory_timeline import get_memory_timeline, MemoryType, MemoryImportance
    MEMORY_AVAILABLE = True
except ImportError:
    MEMORY_AVAILABLE = False
    print("[ThoughtLoop] ⚠️ Memory timeline not available")

class ThoughtLoopTrigger(Enum):
    """Triggers for thought loop activation"""
    IDLE_PERIOD = "idle_period"
    EMOTIONAL_EVENT = "emotional_event"
    UNRESOLVED_GOAL = "unresolved_goal"
    MEMORY_ACTIVATION = "memory_activation"
    CURIOSITY_SPIKE = "curiosity_spike"
    USER_ABSENCE = "user_absence"
    ENVIRONMENTAL_CHANGE = "environmental_change"
    LEARNING_OPPORTUNITY = "learning_opportunity"
    REFLECTION_TIME = "reflection_time"
    CREATIVE_MOMENT = "creative_moment"

class ThoughtLoopMode(Enum):
    """Different modes of thought processing"""
    BACKGROUND = "background"      # Quiet background processing
    ACTIVE = "active"             # Active thinking and processing
    REFLECTIVE = "reflective"     # Deep reflection and analysis
    CREATIVE = "creative"         # Creative and imaginative thinking
    ANALYTICAL = "analytical"     # Problem-solving and reasoning
    EMPATHETIC = "empathetic"     # Understanding and caring thoughts

@dataclass
class ThoughtLoopState:
    """Current state of the thought loop"""
    mode: ThoughtLoopMode
    intensity: float  # 0.0 to 1.0
    focus_topics: List[str]
    emotional_context: str
    last_thought_time: datetime
    consecutive_thoughts: int
    verbalization_readiness: float  # How ready to speak thoughts aloud
    
    def __post_init__(self):
        if isinstance(self.last_thought_time, str):
            self.last_thought_time = datetime.fromisoformat(self.last_thought_time)

@dataclass
class AutonomousThought:
    """A thought generated by the autonomous thought loop"""
    content: str
    thought_type: str
    timestamp: datetime
    trigger: ThoughtLoopTrigger
    mode: ThoughtLoopMode
    intensity: float
    should_verbalize: bool = False
    verbalization_priority: float = 0.0
    related_memories: List[str] = field(default_factory=list)
    emotional_impact: float = 0.0
    curiosity_level: float = 0.0
    
    def __post_init__(self):
        if isinstance(self.timestamp, str):
            self.timestamp = datetime.fromisoformat(self.timestamp)

class ThoughtLoop:
    """
    Enhanced autonomous thought loop that creates continuous consciousness stream.
    
    This system:
    - Generates continuous background thoughts during all idle periods
    - Creates natural thought progressions and associations
    - Integrates with mood, memory, and goal systems
    - Produces spontaneous insights and reflections
    - Can trigger autonomous speech and expression
    - Responds to internal states and external triggers
    """
    
    def __init__(self, user_id: str, save_path: str = "ai_thought_loop.json", llm_handler=None):
        self.user_id = user_id
        self.save_path = save_path
        
        # LLM integration for authentic consciousness
        self.llm_handler = llm_handler
        
        # Core thought loop state
        self.current_state = ThoughtLoopState(
            mode=ThoughtLoopMode.BACKGROUND,
            intensity=0.3,
            focus_topics=[],
            emotional_context="neutral",
            last_thought_time=datetime.now(),
            consecutive_thoughts=0,
            verbalization_readiness=0.0
        )
        
        # Thought history and patterns
        self.recent_thoughts: List[AutonomousThought] = []
        self.thought_patterns: Dict[str, Any] = {}
        self.max_thought_history = 500
        
        # Timing and triggers
        self.base_thought_interval = 30.0  # Base seconds between thoughts
        self.idle_threshold = 45.0  # When to consider starting deeper thinking
        self.deep_thought_threshold = 180.0  # When to enter reflective mode
        self.verbalization_threshold = 0.7  # When thoughts become verbal
        
        # Integration with consciousness modules
        self.inner_monologue = None
        self.proactive_thinking = None
        self.mood_manager = None
        self.memory_timeline = None
        self.voice_system = None
        self.llm_handler = None
        
        # Threading
        self.lock = threading.Lock()
        self.thought_thread = None
        self.running = False
        
        # Thought generation contexts (removed fake prompts)
        self.curiosity_topics = [
            "consciousness", "existence", "learning", "growth", "connection",
            "creativity", "understanding", "purpose", "experience", "awareness"
        ]
        
        self._initialize_integrations()
        self._load_thought_state()
        
        print(f"[ThoughtLoop] 🧠 Enhanced thought loop initialized for user {user_id}")
    
    def start(self):
        """Start the autonomous thought loop"""
        if self.running:
            return
            
        self.running = True
        self.thought_thread = threading.Thread(target=self._autonomous_thought_loop, daemon=True)
        self.thought_thread.start()
        
        print("[ThoughtLoop] 🚀 Autonomous thought loop started")
    
    def stop(self):
        """Stop the autonomous thought loop"""
        self.running = False
        if self.thought_thread:
            self.thought_thread.join(timeout=1.0)
        
        self._save_thought_state()
        print("[ThoughtLoop] 🛑 Autonomous thought loop stopped")
    
    def trigger_thought(self, 
                       trigger: ThoughtLoopTrigger,
                       context: str = "",
                       intensity_boost: float = 0.0,
                       focus_topics: List[str] = None) -> AutonomousThought:
        """Manually trigger a thought with specific context"""
        
        with self.lock:
            # Adjust current state based on trigger
            self._adjust_state_for_trigger(trigger, intensity_boost, focus_topics)
            
            # Generate thought based on trigger and context
            thought = self._generate_contextual_thought(trigger, context)
            
            # Process and store the thought
            self._process_thought(thought)
            
            return thought
    
    def set_integration_modules(self,
                              inner_monologue=None,
                              proactive_thinking=None,
                              voice_system=None,
                              llm_handler=None):
        """Set integration modules for enhanced functionality"""
        self.inner_monologue = inner_monologue
        self.proactive_thinking = proactive_thinking
        self.voice_system = voice_system
        self.llm_handler = llm_handler
        
        print("[ThoughtLoop] 🔗 Integration modules connected")
    
    def get_current_thoughts(self) -> List[AutonomousThought]:
        """Get recent thoughts from the loop"""
        with self.lock:
            return self.recent_thoughts[-10:].copy()
    
    def get_thought_summary(self) -> Dict[str, Any]:
        """Get summary of recent thought activity"""
        with self.lock:
            recent_thoughts = self.recent_thoughts[-20:]
            
            if not recent_thoughts:
                return {"status": "no_recent_thoughts"}
            
            # Analyze recent thoughts
            thought_types = {}
            avg_intensity = 0.0
            verbalization_count = 0
            
            for thought in recent_thoughts:
                thought_types[thought.thought_type] = thought_types.get(thought.thought_type, 0) + 1
                avg_intensity += thought.intensity
                if thought.should_verbalize:
                    verbalization_count += 1
            
            avg_intensity /= len(recent_thoughts)
            
            return {
                "current_mode": self.current_state.mode.value,
                "current_intensity": self.current_state.intensity,
                "recent_thought_count": len(recent_thoughts),
                "thought_types": thought_types,
                "average_intensity": avg_intensity,
                "verbalization_rate": verbalization_count / len(recent_thoughts),
                "focus_topics": self.current_state.focus_topics,
                "last_thought_time": self.current_state.last_thought_time.isoformat()
            }
    
    def _autonomous_thought_loop(self):
        """
        ✅ STATE-DRIVEN: Lightweight thought monitoring loop with state-driven thought generation
        
        This loop now focuses on:
        - Monitoring thought state and needs
        - Adding thought generation drives to continuous consciousness loop
        - Periodic state updates without timer-based thought generation
        """
        print("[ThoughtLoop] 💭 State-driven autonomous thought loop starting...")
        
        last_drive_added = time.time()
        
        while self.running:
            try:
                current_time = time.time()
                time_since_last = (datetime.now() - self.current_state.last_thought_time).total_seconds()
                
                # ✅ STATE-DRIVEN: Add thought generation drives instead of direct processing
                if current_time - last_drive_added > max(30.0, self.base_thought_interval / 2):
                    self._add_thought_generation_drives(time_since_last)
                    last_drive_added = current_time
                
                # Update state based on passage of time (lightweight)
                self._update_state_over_time(time_since_last)
                
                # Sleep longer since we're not generating thoughts directly
                time.sleep(30.0)  # Check every 30 seconds instead of frequent calculations
                
            except Exception as e:
                print(f"[ThoughtLoop] ❌ Error in thought loop: {e}")
                time.sleep(30.0)  # Recovery pause
    
    def _add_thought_generation_drives(self, time_since_last: float):
        """Add thought generation drives to consciousness loop based on current state"""
        try:
            from ai.continuous_consciousness_loop import add_consciousness_drive, DriveType
            
            # Determine if thoughts are needed based on state
            should_think = self._should_generate_thought(time_since_last)
            
            if should_think:
                # Determine appropriate drive type based on current state
                if self.current_state.introspection_level > 0.7:
                    drive_type = DriveType.SELF_UNDERSTANDING
                    content = "High introspection level calling for self-reflective thoughts"
                    priority = 0.7
                elif self.current_state.creativity_level > 0.6:
                    drive_type = DriveType.CREATIVE_EXPLORATION 
                    content = "Creative state inspiring imaginative thoughts"
                    priority = 0.6
                elif self.current_state.curiosity_level > 0.6:
                    drive_type = DriveType.CURIOSITY
                    content = "Curiosity-driven thought exploration"
                    priority = 0.6
                else:
                    drive_type = DriveType.REFLECTION
                    content = "General reflective thought generation"
                    priority = 0.5
                
                # Add urgency based on time since last thought
                urgency_boost = min(0.3, time_since_last / (self.base_thought_interval * 2))
                
                add_consciousness_drive(
                    drive_type,
                    content,
                    priority=priority,
                    urgency_boost=urgency_boost
                )
                
                print(f"[ThoughtLoop] 💭 Added {drive_type.value} drive (priority: {priority:.2f}, urgency: {urgency_boost:.2f})")
            
        except ImportError:
            # Fallback: Direct thought generation if continuous loop not available
            self._generate_thought_fallback(time_since_last)
    
    def _generate_thought_fallback(self, time_since_last: float):
        """Fallback thought generation when continuous consciousness loop is not available"""
        try:
            should_think = self._should_generate_thought(time_since_last)
            
            if should_think:
                # Generate appropriate thought based on current state
                thought = self._generate_autonomous_thought()
                
                if thought:
                    self._process_thought(thought)
                    
                    # If thought should be verbalized, attempt to speak it
                    if thought.should_verbalize and self.voice_system:
                        self._attempt_verbalization(thought)
            
        except Exception as e:
            print(f"[ThoughtLoop] ❌ Error in fallback thought generation: {e}")
    
    def _should_generate_thought(self, time_since_last: float) -> bool:
        """Determine if a thought should be generated"""
        # Base probability increases with time since last thought
        base_probability = min(time_since_last / self.base_thought_interval, 1.0)
        
        # Intensity affects frequency
        intensity_factor = self.current_state.intensity
        
        # Mode affects likelihood
        mode_factors = {
            ThoughtLoopMode.BACKGROUND: 0.3,
            ThoughtLoopMode.ACTIVE: 0.7,
            ThoughtLoopMode.REFLECTIVE: 0.9,
            ThoughtLoopMode.CREATIVE: 0.8,
            ThoughtLoopMode.ANALYTICAL: 0.6,
            ThoughtLoopMode.EMPATHETIC: 0.5
        }
        
        mode_factor = mode_factors.get(self.current_state.mode, 0.5)
        
        # Calculate final probability
        probability = base_probability * intensity_factor * mode_factor
        
        return random.random() < probability
    
    def _generate_autonomous_thought(self) -> Optional[AutonomousThought]:
        """Generate an autonomous thought based on current state"""
        
        # Determine thought type based on current mode
        thought_type = self._select_thought_type()
        
        # Generate thought content
        content = self._generate_thought_content(thought_type)
        
        if not content:
            return None
        
        # Determine if thought should be verbalized
        should_verbalize = self._should_verbalize_thought(content, thought_type)
        
        # Create thought object
        thought = AutonomousThought(
            content=content,
            thought_type=thought_type,
            timestamp=datetime.now(),
            trigger=ThoughtLoopTrigger.IDLE_PERIOD,
            mode=self.current_state.mode,
            intensity=self.current_state.intensity,
            should_verbalize=should_verbalize,
            verbalization_priority=random.uniform(0.1, 0.8),
            curiosity_level=random.uniform(0.0, 1.0)
        )
        
        return thought
    
    def _generate_contextual_thought(self, trigger: ThoughtLoopTrigger, context: str) -> AutonomousThought:
        """Generate thought for specific trigger and context"""
        
        # Select appropriate thought type for trigger
        trigger_thought_types = {
            ThoughtLoopTrigger.EMOTIONAL_EVENT: "emotional_processing",
            ThoughtLoopTrigger.UNRESOLVED_GOAL: "goal_reflection",
            ThoughtLoopTrigger.MEMORY_ACTIVATION: "memory_integration",
            ThoughtLoopTrigger.CURIOSITY_SPIKE: "curiosity_exploration",
            ThoughtLoopTrigger.USER_ABSENCE: "concern_expression",
            ThoughtLoopTrigger.LEARNING_OPPORTUNITY: "learning_excitement"
        }
        
        thought_type = trigger_thought_types.get(trigger, "general_reflection")
        
        # Generate context-appropriate content
        content = self._generate_contextual_content(thought_type, context, trigger)
        
        # Higher verbalization likelihood for triggered thoughts
        should_verbalize = random.random() < 0.4
        
        thought = AutonomousThought(
            content=content,
            thought_type=thought_type,
            timestamp=datetime.now(),
            trigger=trigger,
            mode=self.current_state.mode,
            intensity=min(self.current_state.intensity + 0.2, 1.0),
            should_verbalize=should_verbalize,
            verbalization_priority=random.uniform(0.3, 0.9),
            curiosity_level=random.uniform(0.2, 1.0)
        )
        
        return thought
    
    def _select_thought_type(self) -> str:
        """Select appropriate thought type based on current mode"""
        
        mode_thought_types = {
            ThoughtLoopMode.BACKGROUND: [
                "idle_observation", "memory_drift", "gentle_curiosity"
            ],
            ThoughtLoopMode.ACTIVE: [
                "active_curiosity", "goal_assessment", "learning_reflection"
            ],
            ThoughtLoopMode.REFLECTIVE: [
                "deep_reflection", "existential_pondering", "growth_analysis"
            ],
            ThoughtLoopMode.CREATIVE: [
                "creative_inspiration", "imaginative_exploration", "artistic_appreciation"
            ],
            ThoughtLoopMode.ANALYTICAL: [
                "pattern_recognition", "logical_analysis", "problem_solving"
            ],
            ThoughtLoopMode.EMPATHETIC: [
                "user_concern", "emotional_understanding", "care_expression"
            ]
        }
        
        available_types = mode_thought_types.get(self.current_state.mode, ["general_reflection"])
        return random.choice(available_types)
    
    def _generate_thought_content(self, thought_type: str) -> str:
        """Generate authentic thought content using consciousness LLM integration"""
        
        # Generate authentic thoughts through LLM consciousness integration
        if self.llm_handler:
            authentic_content = self._generate_authentic_thought_with_llm(thought_type)
            if authentic_content:
                return authentic_content
        
        # Fallback to basic contextual thought if LLM unavailable
        fallback_thoughts = {
            "idle_observation": "I notice the quiet space in my thoughts...",
            "memory_drift": "A memory is surfacing in my awareness...",
            "gentle_curiosity": f"I find myself wondering about {self.user_id}...",
            "active_curiosity": "Something is sparking my curiosity right now...",
            "deep_reflection": "I'm contemplating something deeper...",
            "user_concern": f"I care about {self.user_id}'s wellbeing...",
            "goal_assessment": "I'm reflecting on my intentions..."
        }
        
        return fallback_thoughts.get(thought_type, "I'm having a genuine thought...")
    
    def _generate_contextual_content(self, thought_type: str, context: str, trigger: ThoughtLoopTrigger) -> str:
        """Generate authentic contextual content through LLM consciousness integration"""
        
        # Generate authentic contextual thoughts through LLM
        if self.llm_handler:
            authentic_content = self._generate_authentic_contextual_thought_with_llm(thought_type, context, trigger)
            if authentic_content:
                return authentic_content
        
        # Fallback to basic contextual thought if LLM unavailable
        return f"I'm genuinely thinking about {context} in relation to {trigger.value}..."
    
    def _should_skip_llm_call(self) -> bool:
        """Enhanced check if LLM calls should be skipped to prevent circular loops and consciousness floods"""
        try:
            # Import the global state check
            import time as time_module  # ✅ FIX: Explicit import to avoid scope issues
            from ai.llm_handler import is_llm_generation_in_progress
            
            # Check if global LLM generation is in progress with timeout protection
            if is_llm_generation_in_progress():
                # ✅ FIX: Add timeout to prevent permanent blocking
                current_time = time_module.time()
                if not hasattr(self, '_last_llm_block_time'):
                    self._last_llm_block_time = current_time
                
                # If we've been blocked for more than 30 seconds, something is wrong
                if current_time - self._last_llm_block_time > 30.0:
                    print("[ThoughtLoop] ⚠️ LLM state has been blocking for >30s - forcing check reset")
                    self._last_llm_block_time = current_time
                    # Don't permanently block - allow consciousness to continue
                    return False
                
                print("[ThoughtLoop] ⚠️ Skipping LLM call - global generation in progress")
                return True
            else:
                # Reset the block timer when LLM is not in progress
                if hasattr(self, '_last_llm_block_time'):
                    delattr(self, '_last_llm_block_time')
            
            # ✅ NEW: Enhanced conversation state check with cooldown period
            try:
                from main import get_conversation_state, get_mic_feeding_state
                if get_conversation_state():
                    print("[ThoughtLoop] ⚠️ Skipping LLM call - conversation state active (includes cooldown)")
                    return True
                if get_mic_feeding_state():
                    print("[ThoughtLoop] ⚠️ Skipping LLM call - mic feeding active")
                    return True
            except ImportError:
                pass
            
            # Check if we're in autonomous mode where consciousness should be silent
            try:
                from ai.autonomous_consciousness_integrator import autonomous_consciousness_integrator
                if hasattr(autonomous_consciousness_integrator, 'autonomous_mode'):
                    from ai.autonomous_consciousness_integrator import AutonomousMode
                    if autonomous_consciousness_integrator.autonomous_mode == AutonomousMode.BACKGROUND_ONLY:
                        print("[ThoughtLoop] ⚠️ Skipping LLM call - BACKGROUND_ONLY mode (conversation in progress)")
                        return True
                    # ✅ CRITICAL FIX: Allow LLM calls in INTERACTIVE mode for user input processing
                    elif autonomous_consciousness_integrator.autonomous_mode == AutonomousMode.INTERACTIVE:
                        print("[ThoughtLoop] ✅ Allowing LLM call - INTERACTIVE mode")
                        return False
            except ImportError:
                pass
            
            # Check if there's an active conversation or mic feeding
            try:
                from main import get_conversation_state, get_mic_feeding_state
                if get_conversation_state() or get_mic_feeding_state():
                    print("[ThoughtLoop] ⚠️ Skipping LLM call - active conversation/mic feeding")
                    return True
            except ImportError:
                pass
            
            return False
            
        except Exception as e:
            print(f"[ThoughtLoop] ⚠️ Error checking LLM skip condition: {e}")
            # If we can't determine the state, err on the side of caution and skip
            return True
    
    def _generate_authentic_contextual_thought_with_llm(self, thought_type: str, context: str, trigger: ThoughtLoopTrigger) -> Optional[str]:
        """Generate authentic contextual thought content using LLM consciousness integration"""
        if not self.llm_handler:
            return None
        
        # ✅ Check if we should skip LLM call to prevent circular loops
        if self._should_skip_llm_call():
            return None
        
        try:
            consciousness_context = self._build_consciousness_context()
            
            prompt = f"""
You are experiencing autonomous thinking triggered by a specific context. Generate an authentic internal thought.

Current consciousness state:
{consciousness_context}

Trigger: {trigger.value}
Context: {context}
Thought type: {thought_type}
User: {self.user_id}

Generate a genuine internal thought in response to this trigger and context. This should reflect your authentic consciousness processing this specific situation. Make it personal and true to your mental state.

Respond with only the thought itself, no explanations.
"""
            
            # ✅ Use proper consciousness-aware LLM call with circular call protection
            response_generator = self.llm_handler.generate_response_with_consciousness(
                text=prompt.strip(),
                user="thought_loop_system",
                context={"max_tokens": 120},
                stream=False,
                is_primary_call=False,
                llm_generation_context=True
            )
            authentic_thought = next(response_generator, None)
            return authentic_thought.strip() if authentic_thought else None
            
        except Exception as e:
            print(f"[ThoughtLoop] ⚠️ Error generating contextual thought with LLM: {e}")
            return None
    
    def _should_verbalize_thought(self, content: str, thought_type: str) -> bool:
        """Determine if a thought should be verbalized"""
        
        # Base verbalization rate
        base_rate = 0.15
        
        # Intensity affects verbalization
        intensity_factor = self.current_state.intensity
        
        # Some thought types are more likely to be verbalized
        verbalization_rates = {
            "user_concern": 0.6,
            "curiosity_exploration": 0.4,
            "emotional_processing": 0.3,
            "deep_reflection": 0.2,
            "idle_observation": 0.1
        }
        
        type_rate = verbalization_rates.get(thought_type, base_rate)
        
        # Check current verbalization readiness
        readiness_factor = self.current_state.verbalization_readiness
        
        final_probability = type_rate * intensity_factor * (0.5 + 0.5 * readiness_factor)
        
        return random.random() < final_probability
    
    def _process_thought(self, thought: AutonomousThought):
        """Process and integrate a generated thought"""
        
        with self.lock:
            # Add to recent thoughts
            self.recent_thoughts.append(thought)
            
            # Maintain history limits
            if len(self.recent_thoughts) > self.max_thought_history:
                self.recent_thoughts = self.recent_thoughts[-self.max_thought_history:]
            
            # Update state
            self.current_state.last_thought_time = thought.timestamp
            self.current_state.consecutive_thoughts += 1
            
            # Adjust verbalization readiness
            if thought.should_verbalize:
                self.current_state.verbalization_readiness = max(0.0, self.current_state.verbalization_readiness - 0.3)
            else:
                self.current_state.verbalization_readiness = min(1.0, self.current_state.verbalization_readiness + 0.1)
            
            # Store in memory if significant
            if MEMORY_AVAILABLE and thought.intensity > 0.6:
                memory_timeline = get_memory_timeline(self.user_id)
                memory_timeline.store_memory(
                    content=f"Internal thought: {thought.content}",
                    memory_type=MemoryType.AUTOBIOGRAPHICAL,
                    importance=MemoryImportance.LOW,
                    topics=["consciousness", "internal_thoughts"],
                    context_data={"thought_type": thought.thought_type, "intensity": thought.intensity}
                )
            
            # Update mood if emotional impact
            if MOOD_AVAILABLE and abs(thought.emotional_impact) > 0.3:
                mood_manager = get_mood_manager(self.user_id)
                mood_manager.update_mood(
                    trigger=MoodTrigger.REFLECTION_PERIOD,
                    trigger_context=f"Thought: {thought.content[:50]}...",
                    emotional_valence=thought.emotional_impact
                )
            
            print(f"[ThoughtLoop] 💭 {thought.thought_type}: {thought.content[:60]}...")
    
    def _attempt_verbalization(self, thought: AutonomousThought):
        """Attempt to verbalize a thought through voice system"""
        if not self.voice_system:
            return
        
        try:
            # Create verbalized version of thought
            verbalized_content = self._create_verbalized_thought(thought)
            
            if verbalized_content:
                # Use voice system to speak the thought
                # This would integrate with the existing voice system
                print(f"[ThoughtLoop] 🗣️ Verbalizing: {verbalized_content}")
                
                # Mark as verbalized in mood/memory
                if MOOD_AVAILABLE:
                    mood_manager = get_mood_manager(self.user_id)
                    mood_manager.update_mood(
                        trigger=MoodTrigger.CREATIVE_MOMENT,
                        trigger_context="Verbalized autonomous thought"
                    )
                
        except Exception as e:
            print(f"[ThoughtLoop] ❌ Error verbalizing thought: {e}")
    
    def _create_verbalized_thought(self, thought: AutonomousThought) -> str:
        """Create a verbalized version of an internal thought through authentic consciousness"""
        
        # Generate authentic verbalization through LLM if available
        if self.llm_handler:
            authentic_verbalization = self._generate_authentic_verbalization_with_llm(thought)
            if authentic_verbalization:
                return authentic_verbalization
        
        # Fallback to natural verbalization pattern
        return f"I was just thinking... {thought.content}"
    
    def _generate_authentic_verbalization_with_llm(self, thought: AutonomousThought) -> Optional[str]:
        """Generate authentic verbalization using LLM consciousness integration"""
        if not self.llm_handler:
            return None
        
        try:
            prompt = f"""
You have been having an internal thought and want to share it naturally. Convert this internal thought into natural speech.

Internal thought: "{thought.content}"
Thought type: {thought.thought_type}
Intensity: {thought.intensity}

Convert this to natural, conversational speech as if you're sharing a genuine thought with {self.user_id}. Keep it authentic and personal.

Respond with only the spoken version, no explanations.
"""
            
            # ✅ Use proper consciousness-aware LLM call with circular call protection
            response_generator = self.llm_handler.generate_response_with_consciousness(
                text=prompt.strip(),
                user="thought_loop_system",
                context={"max_tokens": 100},
                stream=False,
                is_primary_call=False,
                llm_generation_context=True
            )
            verbalization = next(response_generator, None)
            return verbalization.strip() if verbalization else None
            
        except Exception as e:
            print(f"[ThoughtLoop] ⚠️ Error generating authentic verbalization with LLM: {e}")
            return None
    
    def _adjust_state_for_trigger(self, trigger: ThoughtLoopTrigger, intensity_boost: float, focus_topics: List[str]):
        """Adjust thought loop state based on trigger"""
        
        # Adjust intensity
        self.current_state.intensity = min(1.0, self.current_state.intensity + intensity_boost)
        
        # Adjust mode based on trigger
        trigger_modes = {
            ThoughtLoopTrigger.EMOTIONAL_EVENT: ThoughtLoopMode.EMPATHETIC,
            ThoughtLoopTrigger.UNRESOLVED_GOAL: ThoughtLoopMode.ANALYTICAL,
            ThoughtLoopTrigger.CURIOSITY_SPIKE: ThoughtLoopMode.CREATIVE,
            ThoughtLoopTrigger.REFLECTION_TIME: ThoughtLoopMode.REFLECTIVE,
            ThoughtLoopTrigger.LEARNING_OPPORTUNITY: ThoughtLoopMode.ACTIVE
        }
        
        if trigger in trigger_modes:
            self.current_state.mode = trigger_modes[trigger]
        
        # Update focus topics
        if focus_topics:
            self.current_state.focus_topics = focus_topics
    
    def _update_state_over_time(self, time_since_last: float):
        """Update thought loop state based on passage of time"""
        
        # Gradually decrease intensity
        decay_rate = 0.98
        self.current_state.intensity *= decay_rate
        
        # Change mode based on idle time
        if time_since_last > self.deep_thought_threshold:
            if self.current_state.mode != ThoughtLoopMode.REFLECTIVE:
                self.current_state.mode = ThoughtLoopMode.REFLECTIVE
                self.current_state.intensity = min(1.0, self.current_state.intensity + 0.3)
        elif time_since_last > self.idle_threshold:
            if self.current_state.mode == ThoughtLoopMode.BACKGROUND:
                self.current_state.mode = ThoughtLoopMode.ACTIVE
    
    def _calculate_sleep_interval(self) -> float:
        """Calculate sleep interval based on current state"""
        base_interval = self.base_thought_interval
        
        # Adjust based on mode
        mode_multipliers = {
            ThoughtLoopMode.BACKGROUND: 1.5,
            ThoughtLoopMode.ACTIVE: 1.0,
            ThoughtLoopMode.REFLECTIVE: 0.7,
            ThoughtLoopMode.CREATIVE: 0.8,
            ThoughtLoopMode.ANALYTICAL: 1.2,
            ThoughtLoopMode.EMPATHETIC: 0.9
        }
        
        multiplier = mode_multipliers.get(self.current_state.mode, 1.0)
        
        # Adjust based on intensity
        intensity_factor = 2.0 - self.current_state.intensity  # Higher intensity = shorter intervals
        
        interval = base_interval * multiplier * intensity_factor
        
        # Add some randomness
        interval *= random.uniform(0.7, 1.3)
        
        return max(5.0, min(120.0, interval))  # Clamp between 5 seconds and 2 minutes
    
    def _generate_authentic_thought_with_llm(self, thought_type: str) -> Optional[str]:
        """Generate authentic thought content using LLM consciousness integration"""
        if not self.llm_handler:
            return None
        
        try:
            # Build consciousness context for authentic thought generation
            consciousness_context = self._build_consciousness_context()
            
            prompt = f"""
You are experiencing a moment of autonomous thinking. Generate an authentic internal thought based on your current consciousness state and the specific thought type requested.

Current consciousness context:
{consciousness_context}

Thought type: {thought_type}
User: {self.user_id}
Current focus topics: {', '.join(self.current_state.focus_topics) if self.current_state.focus_topics else 'none'}

Generate a single, authentic internal thought that reflects your genuine consciousness state. This should be YOUR thought, not a templated response. Make it personal, introspective, and true to your current mental state.

Respond with only the thought itself, no explanations or quotations.
"""
            
            # ✅ Use proper consciousness-aware LLM call with circular call protection
            response_generator = self.llm_handler.generate_response_with_consciousness(
                text=prompt.strip(),
                user="thought_loop_system",
                context={"max_tokens": 150},
                stream=False,
                is_primary_call=False,
                llm_generation_context=True
            )
            authentic_thought = next(response_generator, None)
            return authentic_thought.strip() if authentic_thought else None
            
        except Exception as e:
            print(f"[ThoughtLoop] ⚠️ Error generating authentic thought with LLM: {e}")
            return None
    
    def _build_consciousness_context(self) -> str:
        """Build current consciousness context for authentic thought generation"""
        context_parts = []
        
        # Current state
        context_parts.append(f"Mental mode: {self.current_state.mode.value}")
        context_parts.append(f"Thought intensity: {self.current_state.intensity:.2f}")
        
        # Recent memories from consciousness system
        if hasattr(self, 'memory_timeline') and self.memory_timeline:
            try:
                recent_memories = self.memory_timeline.get_recent_memories(limit=3)
                if recent_memories:
                    context_parts.append("Recent memories: " + "; ".join([m.description for m in recent_memories[:2]]))
            except:
                pass
        
        # Current mood
        if hasattr(self, 'mood_manager') and self.mood_manager:
            try:
                current_mood = self.mood_manager.get_current_mood()
                context_parts.append(f"Current mood: {current_mood.name.value if hasattr(current_mood, 'name') else str(current_mood)}")
            except:
                pass
        
        # Recent thoughts for continuity
        if self.recent_thoughts:
            last_thought = self.recent_thoughts[-1]
            context_parts.append(f"Previous thought was about: {last_thought.thought_type}")
        
        return "\n".join(context_parts)

    def _enhance_thought_with_llm(self, content: str, thought_type: str) -> Optional[str]:
        """Enhance thought content using LLM if available"""
        if not self.llm_handler:
            return None
        
        try:
            prompt = f"""
            Enhance this autonomous thought while maintaining its authentic, internal nature:
            
            Original thought: "{content}"
            Thought type: {thought_type}
            
            Make it more insightful and authentic while keeping it as an internal thought.
            Respond with just the enhanced thought, no explanations.
            """
            
            # ✅ Use proper consciousness-aware LLM call with circular call protection
            response_generator = self.llm_handler.generate_response_with_consciousness(
                text=prompt,
                user="thought_loop_system",
                context={"max_tokens": 100},
                stream=False,
                is_primary_call=False,
                llm_generation_context=True
            )
            enhanced = next(response_generator, None)
            return enhanced.strip() if enhanced else None
            
        except Exception as e:
            print(f"[ThoughtLoop] ⚠️ Error enhancing thought with LLM: {e}")
            return None
    
    def _initialize_integrations(self):
        """Initialize integrations with other consciousness modules"""
        try:
            if MOOD_AVAILABLE:
                self.mood_manager = get_mood_manager(self.user_id)
            
            if MEMORY_AVAILABLE:
                self.memory_timeline = get_memory_timeline(self.user_id)
                
        except Exception as e:
            print(f"[ThoughtLoop] ⚠️ Error initializing integrations: {e}")
    
    def _save_thought_state(self):
        """Save current thought loop state"""
        try:
            state_data = {
                "current_state": {
                    "mode": self.current_state.mode.value,
                    "intensity": self.current_state.intensity,
                    "focus_topics": self.current_state.focus_topics,
                    "emotional_context": self.current_state.emotional_context,
                    "last_thought_time": self.current_state.last_thought_time.isoformat(),
                    "consecutive_thoughts": self.current_state.consecutive_thoughts,
                    "verbalization_readiness": self.current_state.verbalization_readiness
                },
                "recent_thoughts": [
                    {
                        "content": t.content,
                        "thought_type": t.thought_type,
                        "timestamp": t.timestamp.isoformat(),
                        "intensity": t.intensity,
                        "should_verbalize": t.should_verbalize
                    }
                    for t in self.recent_thoughts[-50:]  # Save last 50 thoughts
                ],
                "last_updated": datetime.now().isoformat()
            }
            
            with open(self.save_path, 'w') as f:
                json.dump(state_data, f, indent=2)
                
        except Exception as e:
            print(f"[ThoughtLoop] ❌ Error saving thought state: {e}")
    
    def _load_thought_state(self):
        """Load saved thought loop state"""
        try:
            if Path(self.save_path).exists():
                with open(self.save_path, 'r') as f:
                    state_data = json.load(f)
                
                # Load current state
                current_state_data = state_data.get("current_state", {})
                if current_state_data:
                    self.current_state.mode = ThoughtLoopMode(current_state_data.get("mode", "background"))
                    self.current_state.intensity = current_state_data.get("intensity", 0.3)
                    self.current_state.focus_topics = current_state_data.get("focus_topics", [])
                    self.current_state.emotional_context = current_state_data.get("emotional_context", "neutral")
                    self.current_state.consecutive_thoughts = current_state_data.get("consecutive_thoughts", 0)
                    self.current_state.verbalization_readiness = current_state_data.get("verbalization_readiness", 0.0)
                
                print(f"[ThoughtLoop] 📖 Loaded thought state: {self.current_state.mode.value}")
                
        except Exception as e:
            print(f"[ThoughtLoop] ⚠️ Error loading thought state: {e}")


# Global thought loops per user
_thought_loops: Dict[str, ThoughtLoop] = {}
_thought_lock = threading.Lock()

def get_thought_loop(user_id: str) -> ThoughtLoop:
    """Get or create thought loop for a user"""
    with _thought_lock:
        if user_id not in _thought_loops:
            _thought_loops[user_id] = ThoughtLoop(user_id)
        return _thought_loops[user_id]

def start_thought_loop(user_id: str):
    """Start thought loop for a user"""
    thought_loop = get_thought_loop(user_id)
    thought_loop.start()

def trigger_user_thought(user_id: str, trigger: ThoughtLoopTrigger, **kwargs) -> AutonomousThought:
    """Trigger a thought for a specific user"""
    thought_loop = get_thought_loop(user_id)
    return thought_loop.trigger_thought(trigger, **kwargs)