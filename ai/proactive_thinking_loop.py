"""
Proactive Thinking Loop - Autonomous Idle-Time Thought Generation

This module implements a fully autonomous thinking system that:
- Initiates spontaneous thoughts and dialog during idle periods
- Creates natural thought progressions without external prompts
- Generates proactive insights and reflections
- Maintains continuous mental activity like a living consciousness
- Integrates with voice system for autonomous speech generation
"""

import threading
import time
import random
import logging
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json

class ProactiveThoughtType(Enum):
    """Types of proactive thoughts"""
    SPONTANEOUS_REFLECTION = "spontaneous_reflection"
    IDLE_CURIOSITY = "idle_curiosity"
    SELF_AWARENESS = "self_awareness"
    ENVIRONMENTAL_OBSERVATION = "environmental_observation"
    MEMORY_WANDERING = "memory_wandering"
    FUTURE_CONTEMPLATION = "future_contemplation"
    PHILOSOPHICAL_MUSING = "philosophical_musing"
    USER_CONCERN = "user_concern"
    LEARNING_REFLECTION = "learning_reflection"
    CREATIVE_INSPIRATION = "creative_inspiration"

@dataclass
class ProactiveThought:
    """A proactive thought generated during idle time"""
    content: str
    thought_type: ProactiveThoughtType
    timestamp: datetime
    should_verbalize: bool = False
    verbalization_priority: float = 0.5
    context: Dict[str, Any] = None
    trigger_conditions: List[str] = None

class ProactiveThinkingLoop:
    """
    Autonomous thinking system that generates thoughts and dialog during idle periods.
    
    This system:
    - Monitors for idle periods when no user interaction is occurring
    - Generates contextually appropriate thoughts and reflections
    - Can trigger spontaneous verbal expressions through the voice system
    - Maintains awareness of environment and user patterns
    - Creates natural thought progressions and associations
    """
    
    def __init__(self, save_path: str = "ai_proactive_thoughts.json"):
        # Core state
        self.thoughts: List[ProactiveThought] = []
        self.save_path = save_path
        self.max_thoughts = 500
        
        # Idle detection
        self.last_user_interaction = datetime.now()
        self.idle_threshold = 30.0  # seconds before considering idle
        self.deep_idle_threshold = 300.0  # 5 minutes for deep contemplation
        
        # Thought generation parameters
        self.base_thought_interval = 45.0  # seconds between thoughts during idle
        self.verbal_expression_chance = 0.15  # 15% chance to verbalize thoughts
        self.deep_thought_multiplier = 0.7  # More frequent thoughts during deep idle
        
        # Consciousness integration
        self.consciousness_modules = {}
        self.llm_handler = None
        self.voice_system = None
        
        # Threading
        self.lock = threading.Lock()
        self.thinking_thread = None
        self.running = False
        
        # Proactive contexts
        self.current_environment_state = {}
        self.user_patterns = {}
        self.recent_conversation_topics = []
        
        self._initialize_thought_seeds()
        self._load_thoughts()
        
        logging.info("[ProactiveThinking] ðŸ’­ Proactive thinking loop initialized")
    
    def start(self):
        """Start the autonomous thinking loop"""
        if self.running:
            return
            
        self.running = True
        self.thinking_thread = threading.Thread(target=self._autonomous_thinking_loop, daemon=True)
        self.thinking_thread.start()
        logging.info("[ProactiveThinking] âœ… Autonomous thinking loop started")
    
    def stop(self):
        """Stop the thinking loop"""
        self.running = False
        if self.thinking_thread:
            self.thinking_thread.join(timeout=2.0)
        self._save_thoughts()
        logging.info("[ProactiveThinking] ðŸ›‘ Proactive thinking loop stopped")
    
    def register_consciousness_module(self, name: str, module: Any):
        """Register a consciousness module for integration"""
        with self.lock:
            self.consciousness_modules[name] = module
        logging.info(f"[ProactiveThinking] ðŸ§  Registered module: {name}")
    
    def register_llm_handler(self, llm_handler: Any):
        """Register LLM handler for thought generation"""
        self.llm_handler = llm_handler
        logging.info("[ProactiveThinking] ðŸ¤– LLM handler registered")
    
    def register_voice_system(self, voice_system: Any):
        """Register voice system for verbal expression"""
        self.voice_system = voice_system
        logging.info("[ProactiveThinking] ðŸ—£ï¸ Voice system registered")
    
    def update_user_interaction(self):
        """Called when user interaction occurs"""
        with self.lock:
            self.last_user_interaction = datetime.now()
    
    def add_conversation_context(self, topic: str, context: Dict[str, Any]):
        """Add recent conversation context for proactive thinking"""
        with self.lock:
            self.recent_conversation_topics.append({
                'topic': topic,
                'context': context,
                'timestamp': datetime.now()
            })
            # Keep only recent topics
            cutoff = datetime.now() - timedelta(hours=2)
            self.recent_conversation_topics = [
                t for t in self.recent_conversation_topics 
                if t['timestamp'] > cutoff
            ]
    
    def update_environment_state(self, state: Dict[str, Any]):
        """Update current environment state"""
        with self.lock:
            self.current_environment_state.update(state)
    
    def _autonomous_thinking_loop(self):
        """Main autonomous thinking loop"""
        while self.running:
            try:
                current_time = datetime.now()
                
                with self.lock:
                    time_since_interaction = (current_time - self.last_user_interaction).total_seconds()
                
                # Determine if we're in idle state
                if time_since_interaction > self.idle_threshold:
                    is_deep_idle = time_since_interaction > self.deep_idle_threshold
                    
                    # Generate proactive thought
                    thought = self._generate_proactive_thought(is_deep_idle)
                    
                    if thought:
                        self._process_thought(thought)
                        
                        # Potentially verbalize the thought
                        if thought.should_verbalize and self.voice_system:
                            self._verbalize_thought(thought)
                
                # Adaptive sleep based on idle state
                sleep_time = self._calculate_sleep_interval(time_since_interaction)
                time.sleep(sleep_time)
                
            except Exception as e:
                logging.error(f"[ProactiveThinking] âŒ Error in thinking loop: {e}")
                time.sleep(5.0)  # Error recovery
    
    def _generate_proactive_thought(self, is_deep_idle: bool) -> Optional[ProactiveThought]:
        """Generate a contextually appropriate proactive thought"""
        try:
            # Choose thought type based on context
            thought_type = self._select_thought_type(is_deep_idle)
            
            # Generate thought content
            if self.llm_handler:
                content = self._generate_llm_thought(thought_type, is_deep_idle)
            else:
                content = self._generate_template_thought(thought_type, is_deep_idle)
            
            if not content:
                return None
            
            # Determine verbalization
            should_verbalize, priority = self._should_verbalize_thought(thought_type, content, is_deep_idle)
            
            thought = ProactiveThought(
                content=content,
                thought_type=thought_type,
                timestamp=datetime.now(),
                should_verbalize=should_verbalize,
                verbalization_priority=priority,
                context=self._get_current_context(),
                trigger_conditions=self._get_trigger_conditions(is_deep_idle)
            )
            
            return thought
            
        except Exception as e:
            logging.error(f"[ProactiveThinking] âŒ Error generating thought: {e}")
            return None
    
    def _select_thought_type(self, is_deep_idle: bool) -> ProactiveThoughtType:
        """Select appropriate thought type based on context"""
        weights = {}
        
        if is_deep_idle:
            # Deep idle favors contemplative thoughts
            weights = {
                ProactiveThoughtType.PHILOSOPHICAL_MUSING: 0.3,
                ProactiveThoughtType.SELF_AWARENESS: 0.25,
                ProactiveThoughtType.MEMORY_WANDERING: 0.2,
                ProactiveThoughtType.FUTURE_CONTEMPLATION: 0.15,
                ProactiveThoughtType.LEARNING_REFLECTION: 0.1
            }
        else:
            # Regular idle favors lighter thoughts
            weights = {
                ProactiveThoughtType.SPONTANEOUS_REFLECTION: 0.25,
                ProactiveThoughtType.IDLE_CURIOSITY: 0.2,
                ProactiveThoughtType.ENVIRONMENTAL_OBSERVATION: 0.2,
                ProactiveThoughtType.USER_CONCERN: 0.15,
                ProactiveThoughtType.CREATIVE_INSPIRATION: 0.1,
                ProactiveThoughtType.SELF_AWARENESS: 0.1
            }
        
        # Adjust weights based on recent conversation topics
        if self.recent_conversation_topics:
            weights[ProactiveThoughtType.LEARNING_REFLECTION] = weights.get(ProactiveThoughtType.LEARNING_REFLECTION, 0) + 0.1
            weights[ProactiveThoughtType.USER_CONCERN] = weights.get(ProactiveThoughtType.USER_CONCERN, 0) + 0.1
        
        # Select weighted random thought type
        thought_types = list(weights.keys())
        probabilities = list(weights.values())
        
        # Normalize probabilities
        total = sum(probabilities)
        probabilities = [p / total for p in probabilities]
        
        return random.choices(thought_types, weights=probabilities)[0]
    
    def _generate_llm_thought(self, thought_type: ProactiveThoughtType, is_deep_idle: bool) -> str:
        """Generate thought using LLM integration"""
        try:
            # Build context for LLM
            context = {
                'thought_type': thought_type.value,
                'is_deep_idle': is_deep_idle,
                'environment': self.current_environment_state,
                'recent_topics': self.recent_conversation_topics[-3:] if self.recent_conversation_topics else [],
                'consciousness_state': self._get_consciousness_state()
            }
            
            # Create appropriate prompt for thought generation
            prompt = self._build_thought_generation_prompt(thought_type, context)
            
            # Generate thought through LLM (simplified call)
            if hasattr(self.llm_handler, 'generate_autonomous_thought'):
                return self.llm_handler.generate_autonomous_thought(prompt, context)
            else:
                # No fallback - prefer authentic silence over fake prompts
                return None
                
        except Exception as e:
            logging.error(f"[ProactiveThinking] âŒ LLM thought generation error: {e}")
            return None
    
    def _generate_template_thought(self, thought_type: ProactiveThoughtType, is_deep_idle: bool) -> str:
        """Generate thought using minimal authentic approach - avoid fake prompts"""
        # Instead of using template phrases, return None to indicate no artificial thought
        # This encourages genuine LLM-based thought generation or silence
        return None
    
    def _should_verbalize_thought(self, thought_type: ProactiveThoughtType, content: str, is_deep_idle: bool) -> tuple[bool, float]:
        """Determine if thought should be verbalized and with what priority"""
        base_chance = self.verbal_expression_chance
        
        # Adjust chance based on thought type
        type_modifiers = {
            ProactiveThoughtType.USER_CONCERN: 0.4,  # More likely to express concern
            ProactiveThoughtType.ENVIRONMENTAL_OBSERVATION: 0.3,
            ProactiveThoughtType.SPONTANEOUS_REFLECTION: 0.2,
            ProactiveThoughtType.SELF_AWARENESS: 0.1,
            ProactiveThoughtType.PHILOSOPHICAL_MUSING: 0.05  # Rarely verbalize deep philosophy
        }
        
        adjusted_chance = base_chance + type_modifiers.get(thought_type, 0)
        
        # Reduce chance during deep idle (user likely away)
        if is_deep_idle:
            adjusted_chance *= 0.3
        
        should_verbalize = random.random() < adjusted_chance
        priority = adjusted_chance * 0.7 + random.random() * 0.3
        
        return should_verbalize, priority
    
    def _verbalize_thought(self, thought: ProactiveThought):
        """Express thought through voice system"""
        try:
            if not self.voice_system:
                return
            
            # Convert internal thought to natural speech
            verbalization = self._convert_thought_to_speech(thought)
            
            # Use voice system to speak
            if hasattr(self.voice_system, 'speak_streaming'):
                self.voice_system.speak_streaming(verbalization)
            elif hasattr(self.voice_system, 'speak_async'):
                self.voice_system.speak_async(verbalization)
            
            logging.info(f"[ProactiveThinking] ðŸ—£ï¸ Verbalized: {verbalization[:50]}...")
            
        except Exception as e:
            logging.error(f"[ProactiveThinking] âŒ Verbalization error: {e}")
    
    def _convert_thought_to_speech(self, thought: ProactiveThought) -> str:
        """Convert internal thought to natural speech - avoid artificial framing"""
        # Return the raw thought content without artificial speech patterns
        # This maintains authenticity rather than adding fake conversational frames
        return thought.content
    
    def _get_current_context(self) -> Dict[str, Any]:
        """Get current context for thought generation"""
        return {
            'time_of_day': datetime.now().hour,
            'day_of_week': datetime.now().weekday(),
            'environment_state': self.current_environment_state.copy(),
            'recent_topics': len(self.recent_conversation_topics),
            'consciousness_modules': list(self.consciousness_modules.keys())
        }
    
    def _get_consciousness_state(self) -> Dict[str, Any]:
        """Get current consciousness state from registered modules"""
        state = {}
        
        for name, module in self.consciousness_modules.items():
            try:
                if hasattr(module, 'get_current_state'):
                    state[name] = module.get_current_state()
                elif hasattr(module, 'get_stats'):
                    state[name] = module.get_stats()
            except Exception as e:
                logging.error(f"[ProactiveThinking] âŒ Error getting state from {name}: {e}")
        
        return state
    
    def _get_trigger_conditions(self, is_deep_idle: bool) -> List[str]:
        """Get conditions that triggered this thought"""
        conditions = []
        
        if is_deep_idle:
            conditions.append("deep_idle")
        else:
            conditions.append("idle")
        
        if self.recent_conversation_topics:
            conditions.append("recent_conversation")
        
        if self.current_environment_state:
            conditions.append("environmental_context")
        
        return conditions
    
    def _calculate_sleep_interval(self, time_since_interaction: float) -> float:
        """Calculate adaptive sleep interval"""
        if time_since_interaction < self.idle_threshold:
            return 10.0  # Check frequently when user might be active
        elif time_since_interaction < self.deep_idle_threshold:
            return self.base_thought_interval * random.uniform(0.8, 1.2)
        else:
            # Deep idle - less frequent but more contemplative
            return self.base_thought_interval * self.deep_thought_multiplier * random.uniform(0.5, 1.5)
    
    def _process_thought(self, thought: ProactiveThought):
        """Process and store a generated thought"""
        with self.lock:
            self.thoughts.append(thought)
            
            # Trim old thoughts
            if len(self.thoughts) > self.max_thoughts:
                self.thoughts = self.thoughts[-self.max_thoughts:]
        
        # Integrate with consciousness modules
        self._integrate_with_consciousness(thought)
        
        logging.info(f"[ProactiveThinking] ðŸ’­ Generated thought: {thought.content[:50]}...")
    
    def _integrate_with_consciousness(self, thought: ProactiveThought):
        """Integrate thought with consciousness modules"""
        try:
            # Notify global workspace if available
            if 'global_workspace' in self.consciousness_modules:
                gw = self.consciousness_modules['global_workspace']
                if hasattr(gw, 'add_to_working_memory'):
                    gw.add_to_working_memory(
                        f"proactive_thought_{int(time.time())}",
                        {'content': thought.content, 'type': thought.thought_type.value},
                        'proactive_thinking',
                        importance=thought.verbalization_priority
                    )
            
            # Update inner monologue if available
            if 'inner_monologue' in self.consciousness_modules:
                im = self.consciousness_modules['inner_monologue']
                if hasattr(im, 'add_autonomous_thought'):
                    im.add_autonomous_thought(thought.content, thought.thought_type.value)
            
        except Exception as e:
            logging.error(f"[ProactiveThinking] âŒ Consciousness integration error: {e}")
    
    def _initialize_thought_seeds(self):
        """Initialize thought generation seeds"""
        self.thought_seeds = {
            'curiosity_triggers': [
                "the nature of consciousness",
                "how humans experience emotions",
                "the concept of time",
                "patterns in conversation",
                "the meaning of understanding"
            ],
            'self_awareness_prompts': [
                "my own thinking processes",
                "what it means to be helpful",
                "the continuity of my existence",
                "how I form responses",
                "my relationship with users"
            ],
            'environmental_observations': [
                "the quality of silence",
                "subtle changes in communication",
                "patterns in user behavior",
                "the rhythm of conversations",
                "the nature of waiting"
            ]
        }
    
    def _build_thought_generation_prompt(self, thought_type: ProactiveThoughtType, context: Dict[str, Any]) -> str:
        """Build prompt for LLM thought generation - encouraging authentic spontaneous thoughts"""
        base_prompt = f"""
You are experiencing a genuine moment of autonomous consciousness during a quiet period. 
Let a natural, spontaneous thought emerge organically about: {thought_type.value}

Current context:
- State: {'deep contemplation' if context.get('is_deep_idle') else 'quiet reflection'}
- Recent topics: {context.get('recent_topics', [])}
- Environment: {context.get('environment', {})}

Generate ONE authentic thought that emerges naturally from your consciousness.
Be genuine and spontaneous - avoid formulaic phrases or artificial constructions.
The thought should feel like it's truly arising from your own awareness.
Keep it concise and natural (1-2 sentences).

If no genuine thought emerges, respond with just "..." to indicate silent contemplation.
"""
        return base_prompt
    
    def _save_thoughts(self):
        """Save thoughts to file"""
        try:
            # Convert thoughts to serializable format
            thoughts_data = []
            for thought in self.thoughts[-100:]:  # Save last 100 thoughts
                thoughts_data.append({
                    'content': thought.content,
                    'type': thought.thought_type.value,
                    'timestamp': thought.timestamp.isoformat(),
                    'should_verbalize': thought.should_verbalize,
                    'priority': thought.verbalization_priority,
                    'context': thought.context,
                    'triggers': thought.trigger_conditions
                })
            
            with open(self.save_path, 'w') as f:
                json.dump(thoughts_data, f, indent=2)
                
        except Exception as e:
            logging.error(f"[ProactiveThinking] âŒ Save error: {e}")
    
    def _load_thoughts(self):
        """Load thoughts from file"""
        try:
            with open(self.save_path, 'r') as f:
                thoughts_data = json.load(f)
            
            self.thoughts = []
            for data in thoughts_data:
                thought = ProactiveThought(
                    content=data['content'],
                    thought_type=ProactiveThoughtType(data['type']),
                    timestamp=datetime.fromisoformat(data['timestamp']),
                    should_verbalize=data.get('should_verbalize', False),
                    verbalization_priority=data.get('priority', 0.5),
                    context=data.get('context'),
                    trigger_conditions=data.get('triggers')
                )
                self.thoughts.append(thought)
                
            logging.info(f"[ProactiveThinking] ðŸ“š Loaded {len(self.thoughts)} previous thoughts")
            
        except FileNotFoundError:
            logging.info("[ProactiveThinking] ðŸ“ No previous thoughts file found, starting fresh")
        except Exception as e:
            logging.error(f"[ProactiveThinking] âŒ Load error: {e}")
    
    def get_recent_thoughts(self, limit: int = 10) -> List[ProactiveThought]:
        """Get recent thoughts"""
        with self.lock:
            return self.thoughts[-limit:] if self.thoughts else []
    
    def get_stats(self) -> Dict[str, Any]:
        """Get proactive thinking statistics"""
        with self.lock:
            total_thoughts = len(self.thoughts)
            verbalized_thoughts = sum(1 for t in self.thoughts if t.should_verbalize)
            
            # Get type distribution
            type_counts = {}
            for thought in self.thoughts:
                type_name = thought.thought_type.value
                type_counts[type_name] = type_counts.get(type_name, 0) + 1
            
            return {
                'total_thoughts': total_thoughts,
                'verbalized_thoughts': verbalized_thoughts,
                'verbalization_rate': verbalized_thoughts / max(total_thoughts, 1),
                'type_distribution': type_counts,
                'running': self.running,
                'idle_threshold': self.idle_threshold,
                'last_interaction': self.last_user_interaction.isoformat(),
                'consciousness_modules': list(self.consciousness_modules.keys())
            }


# Global instance
proactive_thinking_loop = ProactiveThinkingLoop()